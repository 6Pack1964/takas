#!/usr/bin/python
# -*- coding: utf-8 -*-

import numpy as np
import chainer
from chainer import cuda, Variable, optimizers, serializers
#from chainer import Link, Chain, ChainList
import chainer.functions as F
import chainer.links as L
#from chainer.training import extensions
import time
import datetime
import math
import pyodbc_connect as conn
import matplotlib.pyplot as plt


def createdata_Plus(sic,sqltype,db):


    connection = conn.connectDB(db)
   
    if sqltype=='Comp':
        sql = 'SELECT [SIC],[Data1],[Data2],[TargetData],[NextPeriod] ' \
                'FROM [dbo].[V_MLlab_Estimate_SalesGrowthRatio_stndrdztn2python_train] ' \
                'where [SIC]=? order by [SIC_Order]'
    else:            
#        sql = 'SELECT [SIC],[Data1_Digit],[Data2_Digit],[TargetData_Digit],[NextPeriod],[ThisPeriodSales],[NextPeriodSales] ' \
#                'FROM [dbo].[V_MLlab_Estimate_SalesGrowthRatio_stndrdztn2python_train] ' \
#                'where [Digit_Code]=? and [ThisPeriodSales]<[NextPeriodSales] order by [Serial]'
        sql = 'SELECT [SIC],[Data1_Digit],[Data2_Digit],[TargetData_Digit],[NextPeriod],[ThisPeriodSales],[NextPeriodSales] ' \
                'FROM [dbo].[V_MLlab_Estimate_SalesGrowthRatio_stndrdztn2python_train] ' \
                'where [Digit_Code]=? order by [Serial]'

    cur = connection.cursor()
    cur.execute(sql, sic)
    
    rows = cur.fetchall()
    
    for row in rows:
        #1と２が訓練データ、３が教師データ
      xData_Plus.append((row[1],row[2]))
      yData_Plus.append([row[3]])                                                                           
#      TargetPeriod.append(row[4])
    cur.close()
    connection.close()
#
def createdata_Minus(sic,sqltype,db):


    connection = conn.connectDB(db)
   
    if sqltype=='Comp':
        sql = 'SELECT [SIC],[Data1],[Data2],[TargetData],[NextPeriod] ' \
                'FROM [dbo].[V_MLlab_Estimate_SalesGrowthRatio_stndrdztn2python_train] ' \
                'where [SIC]=? order by [SIC_Order]'
    else:            
        sql = 'SELECT [SIC],[Data1_Digit],[Data2_Digit],[TargetData_Digit],[NextPeriod],[ThisPeriodSales],[NextPeriodSales]' \
                'FROM [dbo].[V_MLlab_Estimate_SalesGrowthRatio_stndrdztn2python_train] ' \
                'where [Digit_Code]=? and [ThisPeriodSales]>[NextPeriodSales] order by [Serial]'

    cur = connection.cursor()
    cur.execute(sql, sic)
    
    rows = cur.fetchall()
    
    for row in rows:
        #1と２が訓練データ、３が教師データ
      xData_Minus.append((row[1],row[2]))
      yData_Minus.append([row[3]])                                                                           
#      TargetPeriod.append(row[4])
    cur.close()
    connection.close()


class MyLSTM(chainer.Chain):
    def __init__(self, h_units):
        super(MyLSTM, self).__init__()
        with self.init_scope():
#            for param in self.params():
#                if param.name == "W" or param.name == "b":
#                    # 標準正規乱数 (平均:0.0, 標準偏差:1.0) 
#                    param.data[...] = np.random.normal(-1, 0, param.data.shape)
                    
            self.l1 = L.Linear(1, h_units)
            self.l2 = L.LSTM(h_units, h_units)            
            self.l3 = L.Linear(h_units, 1)
            self.loss = None
            self.loss_single = None
            #パラメータの初期値
#            self.W = chainer.Parameter(chainer.initializers.Normal(0.05), (10, 5))
#            self.b = chainer.Parameter(0, (5,))

    def __call__(self, x, t):
        with chainer.using_config('train',True),\
             chainer.using_config('autotune',True):
         
            self.reset_state()
                
            cnt = 0
            for i in x:
                #xはばらすのでここでバリアブル型にする
                x_in = Variable(xp.array([[x[cnt]]], xp.float32))
                _h = self.l1(x_in)
                h = self.l2(_h)
                cnt += 1
            y = self.l3(h)
            
            self.loss_single = F.mean_squared_error(y,t)
            self.loss = self.loss_single if self.loss is None \
                                         else self.loss +  self.loss_single
#            loss = F.huber_loss(y,t, delta=1.0, reduce='sum_along_second_axis')[0],y

#            loss = F.mean(F.huber_loss(y,t, delta=1.0)),y
#             return F.huber_loss(y,target,delta=1.0)
#             return F.mean_squared_error(y,target)
            return y

    def GPU_Use(self,gpu):
        #cuda.get_device1のデフォルト値は -1 で、GPUを使用しないことを示す。
        if gpu>=1:
            cuda.get_device(0).use()
            xp = cuda.cupy
            self.to_gpu()
        else:
            xp=np
        
        return xp     

    def loss_calc(self,num,cutchain):
#            print('LOSS:{0}'.format(self.loss.data))
            self.loss =self.loss / float(num) 
#            print('loss_calc:{0}'.format(loss_calc.data))
            self.cleargrads()
            self.loss.backward()
            #バックプロパゲーションの打ち切り。バッチの最後、100回ごとにでカット。
            if cutchain == 1:
                self.loss.unchain_backward()
            optimizer.update()

    def reset_state(self):
        #LSTM層のメモリの初期化
        self.l2.reset_state()

if __name__=='__main__':

    start = time.time()
    NOW=datetime.datetime.now().strftime("%H:%M:%S")
    print('\n\t\tstart_Time：{0}\n'.format(NOW))

    xData_Plus=[]
    yData_Plus=[]
    xData_Minus=[]
    yData_Minus=[]
    xData=[]
    yData=[]
    RecordCnt=0
    input_x=[]
    corect_t=[]
    guessed_y=[]
    t=0
    loss_result=[]
    loss_epoch=[]
    shuffle_num=[]
    minbatchlist=[]
 
    ##########################################

    '''
    SIC
    ---------30	ThisPeriod  SalesDigit<=3（学習できないので40に統合）
    40	ThisPeriod  SalesDigit=4
    51	ThisPeriod  SalesDigit=5  and Sales<20000
    52	ThisPeriod  SalesDigit=5  and Sales>=20000 and  Sales<40000
    53	ThisPeriod  SalesDigit=5  and Sales>=40000 and  Sales<60000
    54	ThisPeriod  SalesDigit=5  and Sales>=60000
    61	ThisPeriod  SalesDigit=6  and Sales<200000
    62	ThisPeriod  SalesDigit=6  and Sales>=200000
    70	ThisPeriod  SalesDigit>=7        
    #'Comp':個別 'Digit'：今期売上高桁数：
    '''
    db = r'EDDB1P'
#    db = r'EDDB1P'
    Target_sql='Digit'
    SIC=40##53

    h_units=128

    model = MyLSTM(h_units)

    gpu=0
    xp = model.GPU_Use(gpu)

#    optimizer = optimizers.AdaDelta(rho=0.9)
    #アルファのディフォルトは0.001（MSEの学習率と同じ
    #ループで逓減していっているので、初期値は大きめにセット
#    optimizer = optimizers.Adam(alpha=0.1)
    optimizer = optimizers.Adam()
    optimizer.setup(model)
#    INITIAL_ALPHA=optimizer.alpha
#    TARGET_ALPHA=0.001
#    print('Initial_optimizer.alpha:{0}'.format(optimizer.alpha))    

    #データ取得
#    createdata(SIC,Target_sql,db)
    createdata_Plus(SIC,Target_sql,db)
#    createdata_Minus(SIC,Target_sql,db)

#    EPOCH = max(int(RecordCnt * 0.5), 500)

    EPOCH=100#1000

    print('Digit_Code:{0}'.format(SIC))
    print('Total_EPOCH:{0}'.format(EPOCH))
#    print('Data_Plus:{0}'.format(len(xData_Plus)))    
#    print('Data_Minus:{0}'.format(len(xData_Minus)))    
    print('Data_Plus:{0}'.format(len(xData_Plus)))    
    print('Data_Minus:{0}'.format(len(xData_Minus)))    

    Lst_accumeloss=None
    accume_loss=0
    minloss = 100
    lst_minloss =100
    PMRate=0
    if len(xData_Minus)>10:
        PMRate=round(float(len(xData_Minus))/float(len(xData_Plus)+len(xData_Minus)))
#    print(PMRate)
#    print(len(xData_Plus))
#    print(len(xData_Minus))
        
    for epoch in range(EPOCH):
        #損失グラフ用、そのEpochで最小のものをプロット        
        minloss = 100
        lst_minloss =0
        #エポック単位でる累計lossを取る用
        accume_loss=0
        xData=[]
        yData=[]
        #偶数の場合は来期が増収となっているデータを使用、奇数は減収
        if len(xData_Minus)>10:

                if epoch>0 or epoch % (20-PMRate) ==0:
                    xData = xData_Minus
                    yData = yData_Minus
                else:
                    xData = xData_Plus
                    yData = yData_Plus
        else:
                xData = xData_Plus
                yData = yData_Plus
        
        data_num=[]
        minbatchlist=[]
        #xDataの全indexを取得
        [data_num.append(q) for q in range(len(xData))]
        #ミニバッチに分ける。想定は10（１０データごとに逆伝播計算を行う）
        if len(data_num)<=15:
           minbatch_num=1
           minbatchlist=[data_num[:]]
        else:
           minbatch_num=math.ceil(len(data_num)/10)    
           minbatchlist=[data_num[i:] if i+ 10 > len(data_num) else data_num[i:i+10] for i in range(0,len(data_num),10)]
        r_1 = 0
        m=0
        #各バッチ数のループ
        for m in range(len(minbatchlist)):
            #LSTMは時系列も考慮しているので、並び替える必要はない。
#            shuffle_num = np.random.permutation(minbatchlist[m])
            shuffle_num=[]
            shuffle_num = minbatchlist[m]
             #Adamの学習率逓減の設定
                #学習率を最終的に0.005にするようバッチごとに逓減している（全エポックの7割時点で最小になる）
#                if round(optimizer.alpha- ALPHA_DECREASE,3) > TARGET_ALPHA or epoch<=200:
#                    optimizer.alpha=round(optimizer.alpha- ALPHA_DECREASE,3)
#                else:
#                    optimizer.alpha = TARGET_ALPHA   
#               print('optimizer.alpha:{0}'.format(optimizer.alpha))    
            #各バッチのループ
            for i in shuffle_num[:]:
                
                x_data =xData[i]
                y_data = Variable(xp.array([yData[i]], xp.float32))
                t = model(x_data, y_data)
                accume_loss +=model.loss_single.data
                lst_minloss = model.loss_single.data
                #グラフ用のプロットデータ （最後のエポックのみ取得）
                if epoch == EPOCH-1:
                    corect_t.append(yData[i][0])
                    guessed_y.append(t.data[0][0])
                    input_x.append(yData[i][0]-xData[i][1])
    
                if epoch == 0 and m==0 and i == shuffle_num[0]:
                    #グラフ用、一番最初のlossをEpochゼロで入れておく
                    loss_result.append(model.loss_single.data)
                    loss_epoch.append(0)
                    print('1st_loss:{0}'.format(model.loss_single.data))
    
                #バッチ単位での最小loss
                if minloss > lst_minloss:
                    minloss = lst_minloss
    #                    print('NewMinloss:\t{0}'.format(minloss))
                
                #パラメータを更新（ミニバッチごと）
                if i == shuffle_num[-1] and m == 0:
                    model.loss_calc(len(shuffle_num),0)
                elif i == shuffle_num[-1] and m >0 and (m+1) % 10 == 0:
                    model.loss_calc(len(shuffle_num),1)
                elif i == shuffle_num[-1] and (m > 0 and (m+1) % 10 > 0): 
                    model.loss_calc(len(shuffle_num),0)
                   
            #イテレータ終了    
            
#            print('EPOCH:{0}/minbatchlist_No:{1}'.format(epoch,m))
            if epoch == (EPOCH - 1) and m == len(minbatchlist)-1 \
                         and i == shuffle_num[-1]:
                print('LstBatch_loss:{0}'.format(minloss))    

            r_1 += 1

        #epochごとに損失を取得（グラフ用）
        loss_result.append(minloss)
        loss_epoch.append(epoch+1)

        #バッチ終了
        #増収・減収を分けているとき、偶数にするとすべて減収データになるので、9にしている
        if epoch>0 and ((epoch + 1) % 9 ==0 or epoch == (EPOCH - 1)):
            print('epoch:{0}'.format(epoch + 1)+'\tAvg_loss:'+ \
                  str(accume_loss/(float(len(shuffle_num))*float(len(minbatchlist)))))
            elapsed = time.time() - start
            NOW=datetime.datetime.now().strftime("%H:%M:%S")
            print('\t\telapsed_Time：{0}'.format(round(elapsed,5))+ '[sec]\tClock:{0}'.format(NOW))

        #1EPOCH終えた時点で最小のものモデルを保存        
        if epoch == 0:
            Lst_accumeloss=accume_loss
            outfile = r'model\{0}'.format(SIC) +'_LSTM.model'
            serializers.save_npz(outfile,model)
        if accume_loss<Lst_accumeloss:
            Lst_accumeloss=accume_loss
            outfile = r'model\{0}'.format(SIC) +'_LSTM.model'
            serializers.save_npz(outfile,model)
            
            
    outfile = r'model\{0}'.format(SIC) +'_LSTMLst.model'
    serializers.save_npz(outfile,model)


    elapsed = time.time() - start
    print('elapsed_TotalTime：{0}'.format(round(elapsed,5))+ '[sec]')

    
    # figureの縦横の大きさ。数字はインチ。デフォルトが(8,6)。
    plt.figure(figsize=(17, 17)) 

    #グラフの縦の個数、グラフの横の個数、グラフ番号
    y_min=min(corect_t)*0.8
    y_max=max(corect_t)*1.2
    ax1 = plt.subplot(3,1,1)
    ax1.set_title('Correct_Graph')
    ax1.set_xlabel('t-x2')
    ax1.set_ylabel('Output_t')
    ax1.grid(True)
    ax1.scatter(input_x,corect_t)
    ax1.set_ylim(y_min, y_max)       
    
    ax2 = plt.subplot(3,1,2)
    ax2.set_title('Guessed_Graph')
    ax2.set_xlabel('t-x2')
    ax2.set_ylabel('Output_y')
    ax2.grid(True)
    ax2.scatter(input_x,guessed_y)
    ax2.set_ylim(y_min, y_max)       
        
    ax3 = plt.subplot(3,1,3)
    ax3.set_yscale('log')
    ax3.set_title('loss per epoch')
    ax3.set_xlabel('Epoch')
    ax3.set_ylabel('loss')
    ax3.grid(True)
    ax3.plot(loss_epoch,loss_result)

#    fig.show()
    plt.savefig(r'evaluation\{0}_{1}_{2}'.format(SIC,h_units,EPOCH)+'.png', dpi=300)
